# -*- coding: utf-8 -*-
"""Entrega3

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YT44e1kAW_lXmOSkNZHqQiUUTZdqr9Y9
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.regularizers import l2
from tensorflow.keras.utils import to_categorical
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px
import plotly.graph_objects as go

df = pd.read_csv('penguins.csv')
df.drop(columns=['id'], inplace=True)
df.head()

df.info()

df.shape

df.describe(include='all')

df_num = df.select_dtypes(include=[np.number])
df_num.head()

print('Covariance:')
df_num.cov()

print('Correlation:')
df_num.corr()

df.isnull().sum()

df[df.isnull().any(axis=1)]

df.drop(columns=['sex'], inplace=True)

df[df.isnull().any(axis=1)]

df.dropna(inplace=True)

df.describe()

df.drop(columns=['year'], inplace=True)

df.head()

df.head()

df['species'].value_counts()

px.bar(df['species'].value_counts())

sns.boxplot(data=df_num, width=0.5,fliersize=5)

sns.pairplot(df, hue="species", size=3,diag_kind="hist")

df.drop(columns=['island','body_mass_g','bill_depth_mm',], inplace=True)

df.head()

# Paso 1: Cargar los datos
data = df

# Paso 2: Preprocesamiento
# Codificar la variable objetivo (species)
label_encoder_species = LabelEncoder()
data['species'] = label_encoder_species.fit_transform(data['species'])

# Seleccionar características (bill_length_mm, flipper_length_mm) y etiquetas (species)
X = data[['bill_length_mm', 'flipper_length_mm']]
y = data['species']

# Estandarizar los datos
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# One-hot encoding de las etiquetas
y_encoded = to_categorical(y)

# Dividir los datos en conjunto de entrenamiento, validación y prueba
X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y_encoded, test_size=0.3, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Imprimir las primeras filas de cada conjunto para observar la separación
print("Datos de Entrenamiento:")
print(pd.DataFrame(X_train, columns=['bill_length_mm', 'flipper_length_mm']).head(), "\n")

print("Datos de Validación:")
print(pd.DataFrame(X_val, columns=['bill_length_mm', 'flipper_length_mm']).head(), "\n")

print("Datos de Prueba:")
print(pd.DataFrame(X_test, columns=['bill_length_mm', 'flipper_length_mm']).head(), "\n")

# Paso 3: Graficar la distribución de las características en los tres conjuntos
fig, axs = plt.subplots(1, 3, figsize=(18, 6))

# Conjunto de Entrenamiento
axs[0].scatter(X_train[:, 0], X_train[:, 1], c=np.argmax(y_train, axis=1), cmap='viridis', label='Train')
axs[0].set_title('Entrenamiento')
axs[0].set_xlabel('Bill Length (mm)')
axs[0].set_ylabel('Flipper Length (mm)')

# Conjunto de Validación
axs[1].scatter(X_val[:, 0], X_val[:, 1], c=np.argmax(y_val, axis=1), cmap='viridis', label='Validation')
axs[1].set_title('Validación')
axs[1].set_xlabel('Bill Length (mm)')
axs[1].set_ylabel('Flipper Length (mm)')

# Conjunto de Prueba
axs[2].scatter(X_test[:, 0], X_test[:, 1], c=np.argmax(y_test, axis=1), cmap='viridis', label='Test')
axs[2].set_title('Prueba')
axs[2].set_xlabel('Bill Length (mm)')
axs[2].set_ylabel('Flipper Length (mm)')

plt.tight_layout()
plt.show()

# Paso 4: Definir el modelo con regularización y dropout
model = Sequential()
model.add(Dense(16, input_dim=2, activation='relu', kernel_regularizer=l2(0.01)))  # Regularización L2
model.add(Dropout(0.2))  # Dropout para prevenir sobreajuste
model.add(Dense(12, activation='relu', kernel_regularizer=l2(0.01)))  # Regularización L2 en capa oculta
model.add(Dropout(0.2))  # Dropout adicional
model.add(Dense(3, activation='softmax'))  # Capa de salida (3 clases)

# Paso 5: Compilar el modelo
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Paso 6: Entrenar el modelo con un conjunto de validación explícito
history = model.fit(X_train, y_train, epochs=100, batch_size=10, verbose=1, validation_data=(X_val, y_val))

# Paso 7: Evaluar el modelo
train_loss, train_accuracy = model.evaluate(X_train, y_train, verbose=1)
val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=1)
test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)

print(f"Train Loss: {train_loss}, Train Accuracy: {train_accuracy}")
print(f"Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}")
print(f"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}")

# Paso 8: Gráficas comparativas del aprendizaje

# Gráfica de la precisión para entrenamiento y validación
plt.figure(figsize=(12, 6))
plt.plot(history.history['accuracy'], label='Entrenamiento')
plt.plot(history.history['val_accuracy'], label='Validación')
plt.title('Precisión del modelo durante el entrenamiento y validación')
plt.xlabel('Épocas')
plt.ylabel('Precisión')
plt.legend()
plt.show()

# Gráfica de la pérdida para entrenamiento y validación
plt.figure(figsize=(12, 6))
plt.plot(history.history['loss'], label='Entrenamiento')
plt.plot(history.history['val_loss'], label='Validación')
plt.title('Pérdida del modelo durante el entrenamiento y validación')
plt.xlabel('Épocas')
plt.ylabel('Pérdida')
plt.legend()
plt.show()

# Paso 9: Predicciones sobre el conjunto de prueba
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true_classes = np.argmax(y_test, axis=1)

# Paso 10: Matriz de confusión
conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)

# Visualizar la matriz de confusión con números
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder_species.classes_, yticklabels=label_encoder_species.classes_)
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

# Paso 11: Reporte de clasificación
# Asegurar que las etiquetas sean correctas y el reporte tenga nombres de clases adecuados
class_names = list(label_encoder_species.classes_)

# Convertir a strings por si acaso
class_names = [str(c) for c in class_names]

print("Classification Report:")
print(classification_report(y_true_classes, y_pred_classes, target_names=class_names))

# Paso 12: Evaluación del grado de varianza
# Grado de varianza se evalúa comparando la precisión de entrenamiento con la de prueba.
# Si el rendimiento es significativamente mejor en entrenamiento que en prueba -> varianza alta.
# Si el rendimiento es similar en ambos -> varianza baja.

# Definir los niveles de varianza
if abs(train_accuracy - test_accuracy) <= 0.05:
    varianza_level = 'Bajo'
elif abs(train_accuracy - test_accuracy) <= 0.1:
    varianza_level = 'Medio'
else:
    varianza_level = 'Alto'

print(f"Grado de Varianza: {varianza_level}")

# Paso 13: Explicación del nivel de ajuste del modelo
# Si el modelo tiene un bajo rendimiento tanto en entrenamiento como en prueba -> underfit.
# Si el modelo tiene un alto rendimiento en entrenamiento pero bajo en prueba -> overfit.
# Si el rendimiento es similar y bueno en ambos -> buen ajuste (fit).

if train_accuracy < 0.7 and test_accuracy < 0.7:
    print("El modelo está subajustado (underfit)")
elif train_accuracy >= 0.85 and test_accuracy < 0.7:
    print("El modelo está sobreajustado (overfit)")
else:
    print("El modelo tiene un ajuste adecuado (fit)")
